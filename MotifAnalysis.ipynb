{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2fca312-bb24-4ff1-9ef6-863d0596d77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from collections import defaultdict\n",
    "import pymfinder as py\n",
    "import json\n",
    "import warnings\n",
    "import math\n",
    "\n",
    "# Load the transaction data\n",
    "df = pd.read_csv('./Debit_Transactions.csv')\n",
    "\n",
    "# Extract relevant columns and remove transactions with emission value < 10\n",
    "df = df[df['transactionFootPrint.carbonEmissionInGrams'] > 10]\n",
    "df = df[['customerId', 'externalParty.merchantCategoryCode', 'createdAt', 'transactionFootPrint.carbonEmissionInGrams', 'amount.value']]\n",
    "\n",
    "# Convert 'createdAt' to datetime and sort by customer and timestamp\n",
    "df['createdAt'] = pd.to_datetime(df['createdAt'])\n",
    "df = df.sort_values(by=['customerId', 'createdAt'])\n",
    "\n",
    "# Remove customers with fewer than 3 unique MCCs\n",
    "df = df.groupby('customerId').filter(lambda x: x['externalParty.merchantCategoryCode'].nunique() > 3)\n",
    "\n",
    "# Filter customers with more than 10 transactions\n",
    "df = df.groupby('customerId').filter(lambda x: len(x) > 10)\n",
    "\n",
    "# Calculate total emissions and total spend per customer\n",
    "customer_totals = df.groupby('customerId').agg(\n",
    "    total_emissions=('transactionFootPrint.carbonEmissionInGrams', 'sum'),\n",
    "    total_spend=('amount.value', 'sum')\n",
    ")\n",
    "\n",
    "# Calculate emission-to-spend ratio\n",
    "customer_totals['emission_to_spend_ratio'] = customer_totals['total_emissions'] / customer_totals['total_spend']\n",
    "\n",
    "# Calculate the 25th and 75th percentiles for the emission-to-spend ratio\n",
    "lower_25th_percentile = customer_totals['emission_to_spend_ratio'].quantile(0.25)\n",
    "upper_75th_percentile = customer_totals['emission_to_spend_ratio'].quantile(0.75)\n",
    "\n",
    "# Add high and low emission classification to customer_totals\n",
    "customer_totals['emission_category'] = pd.cut(\n",
    "    customer_totals['emission_to_spend_ratio'],\n",
    "    bins=[-float('inf'), lower_25th_percentile, upper_75th_percentile, float('inf')],\n",
    "    labels=['Low Emission', 'Medium Emission', 'High Emission']\n",
    ")\n",
    "\n",
    "# Filter customers to include only those in 'Low Emission' and 'High Emission'\n",
    "filtered_customers = customer_totals[\n",
    "    customer_totals['emission_category'].isin(['Low Emission', 'High Emission'])\n",
    "].index\n",
    "\n",
    "# Create transaction sequences by customer with carbon emissions\n",
    "transaction_sequences = df.groupby('customerId').apply(\n",
    "    lambda x: list(zip(x['externalParty.merchantCategoryCode'], x['transactionFootPrint.carbonEmissionInGrams']))\n",
    ").reset_index(name='sequences')\n",
    "\n",
    "# Filter transaction sequences to include only customers in 'Low Emission' and 'High Emission'\n",
    "transaction_sequences = transaction_sequences[\n",
    "    transaction_sequences['customerId'].isin(filtered_customers)\n",
    "]\n",
    "\n",
    "# Create transaction sequences by customer with carbon emissions\n",
    "transaction_sequences = df.groupby('customerId').apply(\n",
    "    lambda x: list(zip(x['externalParty.merchantCategoryCode'], x['transactionFootPrint.carbonEmissionInGrams']))\n",
    ").reset_index(name='sequences')\n",
    "\n",
    "# Filter transaction sequences to include only customers in 'Low Emission' and 'High Emission'\n",
    "transaction_sequences = transaction_sequences[\n",
    "    transaction_sequences['customerId'].isin(filtered_customers)\n",
    "]\n",
    "\n",
    "# Initialize a list to store the results for all customers\n",
    "all_customers_data = []\n",
    "\n",
    "# Mapping of motifs to their initial nodes\n",
    "initial_nodes = {\n",
    "    (6, 0, 1),    # S1\n",
    "    (12, 0, 1),   # S3\n",
    "    (14, 0, 1),   # S7\n",
    "    (36, 0, 2),   # S9\n",
    "    (38, 0, 1),   # S11\n",
    "    (46, 1, 1),   # S14 or S15 (both are initial and have the same structure)\n",
    "    (74, 0, 1),   # S16\n",
    "    (78, 0, 2),   # S19\n",
    "    (98, 0, 1),   # S21\n",
    "    (102, 0, 1),  # S23\n",
    "    (108, 1, 1),  # S25 or S26 (both are initial and have the same structure)\n",
    "    (238, 1, 1)   # S29 or S30 (both are initial and have the same structure)\n",
    "}\n",
    "\n",
    "# Convert initial_nodes to a set of motif IDs\n",
    "initial_node_ids = {id for id, *_ in initial_nodes}\n",
    "\n",
    "# Function to process a single customer\n",
    "def process_customer(customer_id, sequences, emission_category):\n",
    "    G = nx.DiGraph()\n",
    "    edge_freq = defaultdict(int)\n",
    "    edge_emissions = defaultdict(float)\n",
    "    node_emissions = defaultdict(list)  # Store all emissions for calculating average\n",
    "\n",
    "    # Validate sequences format\n",
    "    if not isinstance(sequences, list):\n",
    "        raise TypeError(f\"Sequences for customer {customer_id} are not in the expected format: {type(sequences)}\")\n",
    "\n",
    "    # Add edges, their weights, and carbon emissions\n",
    "    for i in range(len(sequences)):\n",
    "        node_id = sequences[i][0]\n",
    "        emission = sequences[i][1]\n",
    "        if pd.notna(emission):  # Check for NaN emissions\n",
    "            node_emissions[node_id].append(emission)  # Collect emissions for average calculation\n",
    "            if i < len(sequences) - 1:\n",
    "                source = sequences[i][0]\n",
    "                target = sequences[i + 1][0]\n",
    "                edge_freq[(source, target)] += 1\n",
    "                edge_emissions[(source, target)] += sequences[i + 1][1]\n",
    "\n",
    "    total_weight = sum(edge_freq.values())\n",
    "   \n",
    "\n",
    "\n",
    "    # Add edges to the graph with weights and emissions\n",
    "    for (source, target), weight in edge_freq.items():\n",
    "        emission = edge_emissions.get((source, target), 0)\n",
    "        G.add_edge(source, target, weight=weight, emissions=emission)\n",
    "        \n",
    "    graph_file = f'network_graph_{customer_id}.graphml'\n",
    "    nx.write_graphml(G, graph_file)\n",
    "\n",
    "    # Save the network to an edge list file (without emissions for pymfinder)\n",
    "    network_file = f'network_edges_{customer_id}.txt'\n",
    "    with open(network_file, 'w') as file:\n",
    "        for edge in G.edges(data=True):\n",
    "            source, target, data = edge\n",
    "            weight = data['weight']\n",
    "            normalized_weight = (weight / total_weight) * 100\n",
    "            file.write(f\"{source} {target} {normalized_weight}\\n\")\n",
    "\n",
    "    def node_link_to_dict(node_link):\n",
    "        return {\n",
    "            \"id\": node_link.id,\n",
    "            \"motifs\": node_link.motifs,\n",
    "            \"roles\": node_link.roles,\n",
    "            \"weight\": node_link.weight,\n",
    "            \"weighted_motifs\": node_link.weighted_motifs,\n",
    "            \"weighted_roles\": node_link.weighted_roles\n",
    "        }\n",
    "\n",
    "\n",
    "    # Run pymfinder to detect motifs\n",
    "    results = py.pymfinder(\n",
    "        network=network_file,\n",
    "        links=True,\n",
    "        motifsize=3,\n",
    "        stoufferIDs=False,\n",
    "        allmotifs=False,\n",
    "        nrandomizations=1000,\n",
    "        randomize=False,\n",
    "        usemetropolis=False,\n",
    "        networktype=\"unipartite\",\n",
    "        weighted=True\n",
    "\n",
    "    )\n",
    "    \n",
    "    # Extract the data to save\n",
    "    results_dict = {\n",
    "        \"motifs\": { \n",
    "            motif_id: {\n",
    "                \"motif_count\": motif.real,\n",
    "                \"rand\": motif.random_m,\n",
    "                \"srand\": motif.random_sd,\n",
    "                \"zscore\": motif.real_z,\n",
    "                \"weight-mean\": motif.mean_weight,\n",
    "                \"weight-sd\": motif.sd_weight\n",
    "            } for motif_id, motif in results.motifs.items()\n",
    "           \n",
    "        },\n",
    "        \"nodes\": {\n",
    "            node_id: {\n",
    "                \"id\": node.id,\n",
    "                \"motifs\": node.motifs,\n",
    "                \"roles\": node.roles,\n",
    "                \"weighted_motifs\": node.weighted_motifs,\n",
    "                \"weighted_roles\": node.weighted_roles\n",
    "            } for node_id, node in results.nodes.items()\n",
    "        },\n",
    "        \"links\": [node_link_to_dict(link) for _, link in results.links.items()]  # Convert NodeLink to dict\n",
    "    }\n",
    "\n",
    "    # Function to convert tuple keys to strings\n",
    "    def convert_tuple_keys(d):\n",
    "        if isinstance(d, dict):\n",
    "            new_dict = {}\n",
    "            for k, v in d.items():\n",
    "                if isinstance(k, tuple):\n",
    "                    k = str(k)\n",
    "                new_dict[k] = convert_tuple_keys(v)\n",
    "            return new_dict\n",
    "        elif isinstance(d, list):\n",
    "            return [convert_tuple_keys(i) for i in d]\n",
    "        else:\n",
    "            return d\n",
    "\n",
    "    # Convert any tuple keys to strings\n",
    "    results_dict = convert_tuple_keys(results_dict)\n",
    "\n",
    "    # Calculate total emission per motif\n",
    "    motif_emissions = calculate_total_emission_per_motif(G, results_dict['motifs'], results_dict['nodes'], results_dict['links'], node_emissions)\n",
    "\n",
    "    # Prepare the combined results for this customer\n",
    "    customer_data = {\n",
    "        \"customer_id\": customer_id,\n",
    "        \"emission_category\": emission_category,\n",
    "        \"results\": results_dict,\n",
    "        \"motif_emissions\": motif_emissions,\n",
    "        \"graph_file\": graph_file  \n",
    "    }\n",
    "\n",
    "    return customer_data\n",
    "\n",
    "# Function to calculate total emissions per motif for a customer\n",
    "def calculate_total_emission_per_motif(G, motifs, nodes, links, node_emissions):\n",
    "    motif_emissions = defaultdict(float)\n",
    "    added_nodes = defaultdict(set)\n",
    "    motif_link_counts = defaultdict(int)\n",
    "\n",
    "    # Create a dictionary to map links to their motifs\n",
    "    link_motifs = {tuple(link['id']): link['motifs'] for link in links}\n",
    "\n",
    "    # Function to convert role string to a tuple\n",
    "    def role_str_to_tuple(role_str):\n",
    "        return tuple(map(int, role_str.strip('()').split(', ')))\n",
    "\n",
    "    # Iterate through links to calculate emissions for each motif\n",
    "    for link in links:\n",
    "        edge_id = tuple(link['id'])\n",
    "        associated_motifs = link['motifs']\n",
    "        emission = G[edge_id[0]][edge_id[1]].get('emissions', 0)\n",
    "        weight = G[edge_id[0]][edge_id[1]].get('weight', 1)\n",
    "\n",
    "        for motif_id in associated_motifs:\n",
    "            count = link['motifs'][motif_id]\n",
    "            motif_link_counts[motif_id] += count\n",
    "            motif_id_int = int(motif_id)  # Ensure motif_id is an integer\n",
    "\n",
    "            if motif_id_int in initial_node_ids:\n",
    "                # Convert node IDs to string format to access the nodes dictionary\n",
    "                node_id_str_1 = edge_id[0]\n",
    "                node_id_str_2 = edge_id[1]\n",
    "\n",
    "                # Check if node_id_str_1 is in nodes by comparing `id`\n",
    "                node_in_nodes = next((node for node in nodes.values() if node['id'] == int(node_id_str_1)), None)\n",
    "                \n",
    "                if node_in_nodes:\n",
    "                    # Get roles with count > 0\n",
    "                    node_roles = {role: count for role, count in node_in_nodes['roles'].items() if count > 0}\n",
    "                    # Convert roles to tuples for comparison\n",
    "                    node_roles_tuples = {role_str_to_tuple(role) for role in node_roles}\n",
    "                    # Check if any role matches the initial node role for the motif\n",
    "                    for role_tuple in node_roles_tuples:\n",
    "                        if role_tuple in initial_nodes:\n",
    "                            if not (edge_id[0] in added_nodes[motif_id_int]):\n",
    "                                # Calculate initial emission\n",
    "                                if (role_tuple[0] == motif_id_int):\n",
    "                                    initial_emission = sum(node_emissions.get(edge_id[0], [])) / len(node_emissions.get(edge_id[0], [1]))\n",
    "                                    initial_emission *= node_roles.get(str(role_tuple), 0)  # Multiply by count\n",
    "                                    motif_emissions[motif_id_int] += initial_emission\n",
    "                                    added_nodes[motif_id_int].add(edge_id[0])\n",
    "\n",
    "            # Accumulate emission for the motif, but only if it's a valid number\n",
    "            if not math.isnan(emission):\n",
    "                motif_emissions[motif_id_int] += emission * (link['motifs'][motif_id] / weight)\n",
    "  \n",
    "    # Return results\n",
    "    #print(motif_emissions)\n",
    "    return motif_emissions\n",
    "\n",
    "# Process each customer and store results\n",
    "for customer_id, sequences in transaction_sequences.values:\n",
    "    print(f\"Processing customer {customer_id}\")\n",
    "    try:\n",
    "        emission_category = customer_totals.loc[customer_id, 'emission_category']\n",
    "        customer_data = process_customer(customer_id, sequences, emission_category)\n",
    "        all_customers_data.append(customer_data)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing customer {customer_id}: {e}\")\n",
    "\n",
    "# Save all results to a JSON file\n",
    "with open('motif_results_weight_emission_25_1000.json', 'w') as f:\n",
    "    json.dump(all_customers_data, f, indent=4)\n",
    "\n",
    "print(\"All customer results have been processed and saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "492ce1fb-52be-41ee-a190-874e4304d916",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166\n"
     ]
    }
   ],
   "source": [
    "print(len(transaction_sequences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3211807-348e-43d6-abcb-23704864f637",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
